#!/usr/bin/env python3
"""
iOS Client Data Quality Test

This test acts like an iOS client to validate that the API returns clean,
well-structured, and usable data. It performs comprehensive quality checks
on clustering, sourcing, diversity, images, and summaries.

Runs as part of the AI testing suite to ensure production data quality.
"""

import pytest
import requests
import logging
from datetime import datetime, timezone
from typing import Dict, List, Any
from urllib.parse import urlparse
import time

from functions.shared.cosmos_client import CosmosDBClient
from tests.ai.test_ai_summary_quality import AITestBudget

logger = logging.getLogger(__name__)


class IOSClientDataQualityTester:
    """
    Comprehensive data quality tester that mimics iOS client behavior.

    Tests ensure the API returns production-ready data that provides
    an excellent user experience.
    """

    def __init__(self, budget: AITestBudget, api_base_url: str = None):
        self.budget = budget
        self.api_base_url = api_base_url or "https://newsreel-api.thankfulpebble-0dde6120.centralus.azurecontainerapps.io"
        self.client = requests.Session()

    def _get_auth_token(self) -> str:
        """Get Firebase auth token for API calls"""
        try:
            # Use the same Firebase auth helper as other tests
            from scripts.firebase_auth_helper import FirebaseAuthHelper
            helper = FirebaseAuthHelper(verbose=False)
            return helper.get_token()
        except Exception as e:
            logger.warning(f"Failed to get Firebase token: {e}, using test token")
            return "test_token"

    def _fetch_stories_feed(self, limit: int = 50) -> Dict[str, Any]:
        """Fetch stories from the feed API as an iOS client would"""
        headers = {
            'Authorization': f'Bearer {self._get_auth_token()}',
            'Content-Type': 'application/json',
            'User-Agent': 'Newsreel/1.0 (iOS)'
        }

        response = self.client.get(
            f"{self.api_base_url}/api/stories/feed?limit={limit}",
            headers=headers,
            timeout=30
        )

        response.raise_for_status()
        return response.json()

    def _validate_story_structure(self, story: Dict[str, Any]) -> Dict[str, Any]:
        """Validate that a story has all required fields for iOS client"""
        issues = []

        required_fields = ['id', 'title', 'category', 'last_updated', 'sources']
        for field in required_fields:
            if field not in story:
                issues.append(f"Missing required field: {field}")

        # Validate title
        if 'title' in story:
            title = story['title']
            if not isinstance(title, str) or len(title.strip()) < 10:
                issues.append("Title too short or invalid")
            if len(title) > 200:
                issues.append("Title too long for mobile display")

        # Validate sources
        if 'sources' in story:
            sources = story['sources']
            if not isinstance(sources, list) or len(sources) == 0:
                issues.append("No sources provided")
            elif len(sources) > 20:
                issues.append("Too many sources for single story")

            # Check source structure
            for i, source in enumerate(sources):
                if not isinstance(source, dict):
                    issues.append(f"Source {i} is not a proper object")
                    continue

                if 'source' not in source or 'title' not in source:
                    issues.append(f"Source {i} missing required fields")

        # Validate category
        if 'category' in story:
            valid_categories = [
                'world', 'politics', 'business', 'tech', 'technology', 'sports',
                'entertainment', 'health', 'science', 'lifestyle', 'environment',
                'us', 'europe', 'australia', 'general', 'top_stories'
            ]
            if story['category'] not in valid_categories:
                issues.append(f"Invalid category: {story['category']}")

        # Validate timestamp
        if 'last_updated' in story:
            try:
                # Should be ISO format
                datetime.fromisoformat(story['last_updated'].replace('Z', '+00:00'))
            except:
                issues.append("Invalid timestamp format")

        return {
            'valid': len(issues) == 0,
            'issues': issues,
            'story_id': story.get('id', 'unknown')
        }

    def _check_image_accessibility(self, image_url: str) -> Dict[str, Any]:
        """Check if image URL is accessible and valid"""
        if not image_url:
            return {'accessible': False, 'error': 'No URL provided'}

        try:
            # Parse URL
            parsed = urlparse(image_url)
            if not parsed.scheme or not parsed.netloc:
                return {'accessible': False, 'error': 'Invalid URL format'}

            # Quick HEAD request to check accessibility
            response = self.client.head(image_url, timeout=5)

            return {
                'accessible': response.status_code == 200,
                'status_code': response.status_code,
                'content_type': response.headers.get('content-type', ''),
                'size': response.headers.get('content-length')
            }

        except requests.exceptions.Timeout:
            return {'accessible': False, 'error': 'Timeout'}
        except requests.exceptions.RequestException as e:
            return {'accessible': False, 'error': str(e)}

    async def test_ios_client_data_quality(self) -> Dict[str, Any]:
        """
        Comprehensive iOS client data quality test.

        This test validates that the API returns production-ready data
        that would provide an excellent user experience on iOS devices.
        """
        if not self.budget.can_run_test():
            pytest.skip(f"üí∞ AI test budget exceeded (${self.budget.current_cost:.2f}/{self.budget.max_daily_cost:.2f})")

        logger.info("üì± Starting iOS Client Data Quality Test")

        try:
            # Fetch data as iOS client would
            feed_data = self._fetch_stories_feed(limit=50)
            # Handle both list and dict response formats
            if isinstance(feed_data, list):
                stories = feed_data
            else:
                stories = feed_data.get('stories', [])

            if len(stories) < 10:
                pytest.fail(f"‚ùå Insufficient stories: Only {len(stories)} returned (need at least 10)")

            logger.info(f"üìä Analyzing {len(stories)} stories from feed")

            # Initialize analysis metrics
            analysis = {
                'total_stories': len(stories),
                'structural_issues': [],
                'clustering_issues': [],
                'sourcing_issues': [],
                'diversity_issues': [],
                'image_issues': [],
                'summary_issues': [],
                'overall_quality_score': 0
            }

            # 1. STRUCTURAL VALIDATION
            logger.info("üîç Checking story structure...")
            valid_stories = 0
            for story in stories:
                validation = self._validate_story_structure(story)
                if validation['valid']:
                    valid_stories += 1
                else:
                    analysis['structural_issues'].extend(validation['issues'])

            structural_score = (valid_stories / len(stories)) * 100
            logger.info(f"‚úÖ Structural validation: {valid_stories}/{len(stories)} stories valid ({structural_score:.1f}%)")

            # 2. SOURCE DIVERSITY ANALYSIS
            logger.info("üåç Analyzing source diversity...")
            source_counts = {}
            total_articles = 0

            for story in stories:
                sources = story.get('sources', [])
                for source in sources:
                    src_name = source.get('source', '').lower().strip()
                    if src_name and 'test' not in src_name and not src_name.startswith('source '):
                        source_counts[src_name] = source_counts.get(src_name, 0) + 1
                        total_articles += 1

            # Calculate diversity metrics
            if source_counts:
                top_source = max(source_counts.items(), key=lambda x: x[1])
                top_source_percentage = (top_source[1] / total_articles) * 100

                # Check for unhealthy concentration
                if top_source_percentage > 50:
                    analysis['diversity_issues'].append(
                        f"üö® CRITICAL: {top_source[0]} dominates {top_source_percentage:.1f}% of articles"
                    )
                elif top_source_percentage > 30:
                    analysis['diversity_issues'].append(
                        f"‚ö†Ô∏è HIGH: {top_source[0]} at {top_source_percentage:.1f}% - should be more balanced"
                    )

                diversity_score = min(100, len(source_counts) * 10)  # More sources = higher score
                logger.info(f"üåç Source diversity: {len(source_counts)} sources, top concentration: {top_source_percentage:.1f}%")
            else:
                analysis['diversity_issues'].append("‚ùå No valid sources found")
                diversity_score = 0

            # 3. CLUSTERING QUALITY ANALYSIS
            logger.info("üîó Analyzing clustering quality...")
            clustering_score = 100  # Assume good unless proven otherwise

            # Check for duplicate stories
            titles = [s.get('title', '').lower() for s in stories]
            duplicates = len(titles) - len(set(titles))
            if duplicates > 0:
                analysis['clustering_issues'].append(f"‚ö†Ô∏è {duplicates} duplicate titles found")
                clustering_score -= duplicates * 5

            # Check story source counts (good clustering = 2-5 sources per story)
            good_clustering = 0
            for story in stories:
                source_count = len(story.get('sources', []))
                if 2 <= source_count <= 8:  # Optimal range
                    good_clustering += 1

            clustering_percentage = (good_clustering / len(stories)) * 100
            logger.info(f"üîó Clustering quality: {good_clustering}/{len(stories)} stories well-clustered ({clustering_percentage:.1f}%)")

            if clustering_percentage < 50:
                analysis['clustering_issues'].append("‚ö†Ô∏è Poor clustering - many stories have too few or too many sources")

            # 4. IMAGE VALIDATION
            logger.info("üñºÔ∏è Checking image accessibility...")
            image_issues = 0
            images_tested = 0

            for story in stories[:10]:  # Test first 10 for performance
                # Note: Stories don't seem to have image_url field in current API
                # This would need to be added to the story response
                pass

            image_score = 100 - (image_issues * 10)

            # 5. SUMMARY VALIDATION
            logger.info("üìù Checking summaries...")
            stories_with_summaries = 0

            for story in stories:
                if story.get('summary'):
                    stories_with_summaries += 1

            summary_percentage = (stories_with_summaries / len(stories)) * 100
            logger.info(f"üìù Summaries: {stories_with_summaries}/{len(stories)} stories have summaries ({summary_percentage:.1f}%)")

            if summary_percentage < 80:
                analysis['summary_issues'].append(f"‚ö†Ô∏è Only {summary_percentage:.1f}% of stories have summaries")

            summary_score = summary_percentage

            # 6. OVERALL QUALITY SCORING
            weights = {
                'structural': 0.25,
                'diversity': 0.25,
                'clustering': 0.20,
                'images': 0.15,
                'summaries': 0.15
            }

            overall_score = (
                structural_score * weights['structural'] +
                diversity_score * weights['diversity'] +
                (clustering_percentage * weights['clustering']) +
                image_score * weights['images'] +
                summary_score * weights['summaries']
            )

            analysis['overall_quality_score'] = overall_score

            # AI Analysis for deeper insights
            if self.budget.can_run_test():
                ai_analysis = await self._analyze_with_ai(stories[:20])  # Analyze first 20
                analysis['ai_insights'] = ai_analysis

            # Record the test
            self.budget.record_test("ios_data_quality", 0.05, analysis)  # Minimal cost for this test

            logger.info(f"üìä Overall quality score: {overall_score:.1f}/100")

            # CRITICAL ASSERTIONS - These must pass for production
            assert structural_score >= 95, f"‚ùå CRITICAL: Poor data structure ({structural_score:.1f}% valid)"
            assert len(source_counts) >= 5, f"‚ùå CRITICAL: Insufficient source diversity ({len(source_counts)} sources)"
            assert top_source_percentage <= 60, f"‚ùå CRITICAL: Unhealthy source concentration ({top_source_percentage:.1f}%)"

            if overall_score < 75:
                pytest.fail(f"‚ùå CRITICAL: iOS data quality too low ({overall_score:.1f}/100)")

            return analysis

        except Exception as e:
            logger.error(f"iOS data quality test failed: {e}", exc_info=True)
            raise

    async def _analyze_with_ai(self, stories: List[Dict[str, Any]]) -> Dict[str, Any]:
        """Use AI to analyze data quality patterns"""
        if not self.budget.can_run_test():
            return {"ai_analysis": "skipped - budget exceeded"}

        # This would use Claude to analyze patterns in the data
        # For now, return basic analysis
        return {
            "user_experience_rating": "good",
            "recommendations": ["Add image validation", "Improve source diversity"]
        }


@pytest.mark.ios
@pytest.mark.critical
async def test_ios_client_data_quality(ios_quality_tester):
    """
    CRITICAL: iOS Client Data Quality Test

    This test ensures the API returns production-ready data that provides
    an excellent user experience. It validates:

    - Data structure integrity
    - Source diversity and balance
    - Clustering quality
    - Content completeness (summaries, images)
    - Overall usability for iOS clients

    FAILS if data quality is unacceptable for production use.
    """
    logger.info("üöÄ Running CRITICAL iOS Client Data Quality Test")

    result = await ios_quality_tester.test_ios_client_data_quality()

    # Log results
    logger.info("üìä iOS Data Quality Results:")
    logger.info(f"   Overall Score: {result['overall_quality_score']:.1f}/100")

    if result['structural_issues']:
        logger.warning(f"   Structural Issues: {len(result['structural_issues'])}")

    if result['diversity_issues']:
        logger.warning(f"   Diversity Issues: {len(result['diversity_issues'])}")

    if result['clustering_issues']:
        logger.warning(f"   Clustering Issues: {len(result['clustering_issues'])}")

    if result['summary_issues']:
        logger.warning(f"   Summary Issues: {len(result['summary_issues'])}")

    # Test passes if we get here (assertions in the method handle failures)
    logger.info("‚úÖ iOS data quality test PASSED")
