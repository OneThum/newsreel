#!/usr/bin/env python3
"""
Simple validation script for clustering overhaul components.

This script validates that all clustering components can be imported and
perform basic functionality without complex test framework dependencies.
"""

import sys
import os
import json
from pathlib import Path

# Add the functions directory to path
functions_path = os.path.join(os.path.dirname(__file__), '..')
sys.path.insert(0, functions_path)
print(f"Added to path: {functions_path}")
print(f"Current path: {sys.path[:3]}")

def validate_imports():
    """Validate that all components can be imported"""
    print("ğŸ” Validating component imports...")

    components = []
    errors = []

    try:
        from functions.shared.config import config
        print("âœ… Config imported successfully")
        components.append("config")
    except Exception as e:
        print(f"âŒ Config import failed: {e}")
        errors.append(f"config: {e}")

    try:
        from functions.shared.utils import extract_simple_entities, extract_simple_entities_with_wikidata
        print("âœ… Utils imported successfully")
        components.append("utils")
    except Exception as e:
        print(f"âŒ Utils import failed: {e}")
        errors.append(f"utils: {e}")

    try:
        from functions.shared.wikidata_linking import WikidataLinker
        print("âœ… Wikidata linking imported successfully")
        components.append("wikidata_linking")
    except Exception as e:
        print(f"âŒ Wikidata linking import failed: {e}")
        errors.append(f"wikidata_linking: {e}")

    try:
        from functions.shared.event_signatures import extract_event_signature
        print("âœ… Event signatures imported successfully")
        components.append("event_signatures")
    except Exception as e:
        print(f"âŒ Event signatures import failed: {e}")
        errors.append(f"event_signatures: {e}")

    try:
        from functions.shared.geographic_features import extract_geographic_features
        print("âœ… Geographic features imported successfully")
        components.append("geographic_features")
    except Exception as e:
        print(f"âŒ Geographic features import failed: {e}")
        errors.append(f"geographic_features: {e}")

    try:
        from functions.shared.vector_index import VectorIndex
        print("âœ… Vector index imported successfully")
        components.append("vector_index")
    except Exception as e:
        print(f"âŒ Vector index import failed: {e}")
        errors.append(f"vector_index: {e}")

    try:
        from functions.shared.cluster_maintenance import ClusterMaintenance
        print("âœ… Cluster maintenance imported successfully")
        components.append("cluster_maintenance")
    except Exception as e:
        print(f"âŒ Cluster maintenance import failed: {e}")
        errors.append(f"cluster_maintenance: {e}")

    # ML components (optional)
    try:
        from functions.shared.scoring_optimization import OptimizedSimilarityScorer
        print("âœ… ML scoring imported successfully (optional)")
        components.append("scoring_optimization")
    except Exception as e:
        print(f"âš ï¸ ML scoring not available (optional): {e}")

    try:
        from functions.shared.training_data import TrainingDataGenerator
        print("âœ… Training data imported successfully (optional)")
        components.append("training_data")
    except Exception as e:
        print(f"âš ï¸ Training data not available (optional): {e}")

    return components, errors

def validate_basic_functionality():
    """Validate basic functionality of imported components"""
    print("\nğŸ”§ Validating basic functionality...")

    results = []
    errors = []

    # Test entity extraction
    try:
        from functions.shared.utils import extract_simple_entities
        entities = extract_simple_entities("Apple announces new iPhone in California")
        assert len(entities) > 0, "Entity extraction returned no entities"
        print("âœ… Entity extraction works")
        results.append("entity_extraction")
    except Exception as e:
        print(f"âŒ Entity extraction failed: {e}")
        errors.append(f"entity_extraction: {e}")

    # Test event signature extraction
    try:
        from functions.shared.event_signatures import extract_event_signature
        signature = extract_event_signature(
            "Apple launches iPhone",
            "Apple released the new iPhone model",
            [{"text": "Apple", "type": "ORGANIZATION"}]
        )
        assert "event_types" in signature, "Event signature missing event_types"
        assert len(signature["event_types"]) > 0, "No event types extracted"
        print("âœ… Event signature extraction works")
        results.append("event_signatures")
    except Exception as e:
        print(f"âŒ Event signature extraction failed: {e}")
        errors.append(f"event_signatures: {e}")

    # Test geographic features
    try:
        from functions.shared.geographic_features import extract_geographic_features
        geo = extract_geographic_features(
            "Earthquake in California",
            "A quake struck Northern California",
            [{"text": "California", "type": "LOCATION"}]
        )
        assert "locations" in geo, "Geographic extraction missing locations"
        print("âœ… Geographic feature extraction works")
        results.append("geographic_features")
    except Exception as e:
        print(f"âŒ Geographic feature extraction failed: {e}")
        errors.append(f"geographic_features: {e}")

    # Test vector index
    try:
        from functions.shared.vector_index import VectorIndex
        index = VectorIndex(embedding_dim=64)  # Small dimension for testing
        assert index.index is not None, "Vector index not initialized"
        print("âœ… Vector index initialization works")
        results.append("vector_index")
    except Exception as e:
        print(f"âŒ Vector index initialization failed: {e}")
        errors.append(f"vector_index: {e}")

    return results, errors

def validate_ground_truth_dataset():
    """Validate the ground truth dataset"""
    print("\nğŸ“Š Validating ground truth dataset...")

    dataset_path = Path(__file__).parent / "ground_truth_dataset.json"

    if not dataset_path.exists():
        print("âŒ Ground truth dataset not found")
        return False, ["Ground truth dataset file missing"]

    try:
        with open(dataset_path, 'r') as f:
            data = json.load(f)

        dataset = data["dataset"]
        metadata = data["metadata"]

        # Basic validation
        assert len(dataset) > 0, "Dataset is empty"
        assert "positive_pairs" in metadata, "Missing positive pairs count"
        assert "negative_pairs" in metadata, "Missing negative pairs count"

        positive_count = metadata["positive_pairs"]
        negative_count = metadata["negative_pairs"]

        assert positive_count > 0, "No positive pairs in dataset"
        assert negative_count > 0, "No negative pairs in dataset"

        print(f"âœ… Ground truth dataset valid: {len(dataset)} pairs")
        print(f"   Positive pairs: {positive_count}")
        print(f"   Negative pairs: {negative_count}")

        return True, []

    except Exception as e:
        print(f"âŒ Ground truth dataset validation failed: {e}")
        return False, [str(e)]

def generate_validation_report():
    """Generate a comprehensive validation report"""
    print("\nğŸ“‹ Generating validation report...")

    # Run all validations
    imported_components, import_errors = validate_imports()
    functional_components, functional_errors = validate_basic_functionality()
    dataset_valid, dataset_errors = validate_ground_truth_dataset()

    # Create report
    report = {
        "timestamp": "2025-11-12T22:00:00Z",
        "validation_results": {
            "imports": {
                "successful": imported_components,
                "errors": import_errors
            },
            "functionality": {
                "successful": functional_components,
                "errors": functional_errors
            },
            "dataset": {
                "valid": dataset_valid,
                "errors": dataset_errors
            }
        },
        "overall_status": "PASS" if not (import_errors or functional_errors or dataset_errors) else "FAIL",
        "recommendations": []
    }

    # Add recommendations based on results
    if import_errors:
        report["recommendations"].append("Fix import errors for failed components")

    if functional_errors:
        report["recommendations"].append("Debug functionality issues in failed components")

    if dataset_errors:
        report["recommendations"].append("Regenerate or fix ground truth dataset")

    if not any(comp in imported_components for comp in ["scoring_optimization", "training_data"]):
        report["recommendations"].append("Install scikit-learn for ML components: pip install scikit-learn pandas")

    # Save report
    report_path = Path(__file__).parent / "validation_report.json"
    with open(report_path, 'w') as f:
        json.dump(report, f, indent=2)

    print(f"âœ… Validation report saved to {report_path}")

    # Print summary
    print("\nğŸ¯ VALIDATION SUMMARY:")
    print(f"   Overall Status: {report['overall_status']}")
    print(f"   Components Imported: {len(imported_components)}")
    print(f"   Functional Tests Passed: {len(functional_components)}")
    print(f"   Dataset Valid: {dataset_valid}")

    if report["recommendations"]:
        print("\nğŸ’¡ RECOMMENDATIONS:")
        for rec in report["recommendations"]:
            print(f"   â€¢ {rec}")

    return report

if __name__ == "__main__":
    print("ğŸš€ Starting Clustering Overhaul Validation")
    print("=" * 50)

    report = generate_validation_report()

    print("\n" + "=" * 50)
    if report["overall_status"] == "PASS":
        print("ğŸ‰ VALIDATION PASSED! Ready for deployment.")
        sys.exit(0)
    else:
        print("âŒ VALIDATION FAILED! Check errors above.")
        sys.exit(1)
